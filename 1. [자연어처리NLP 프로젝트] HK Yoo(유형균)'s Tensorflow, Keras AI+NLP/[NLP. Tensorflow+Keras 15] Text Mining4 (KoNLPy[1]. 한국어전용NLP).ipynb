{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[NLP. Tensorflow+Keras 15] Text Mining4 (KoNLPy[1]. 한국어전용NLP).ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"x2gLm3D9agx8","colab_type":"text"},"source":["# KoNLPy를 통한 한국어 자연어처리 (Korean Natural Language Processing [NLP]) by  유형균"]},{"cell_type":"code","metadata":{"id":"SbmuA9c8uS4q","colab_type":"code","outputId":"7997f4ed-914c-4d31-d1f0-07ad883630df","executionInfo":{"status":"ok","timestamp":1563849640191,"user_tz":-540,"elapsed":25641,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}},"colab":{"base_uri":"https://localhost:8080/","height":562}},"source":["##### ------------------ 본 한글주석 by 유형균 (이메일 문의 : quantgeni@gmail.com) ------------------ #####\n","\n","# KoNLPy 분석기 중, Okt, 즉 구 Twitter가 간편+강력\n","\n","# 다양한 색상 팔레트를 이용한 워드클라우드\n","# jiffyclub.github.io/palettable\n","\n","# 여러가지 배색들을 도와주는 패키지\n","\n","\n","\n","!pip install konlpy\n","import konlpy\n","from konlpy.tag import Hannanum\n","from konlpy.tag import Kkma\n","from konlpy.tag import Komoran\n","from konlpy.tag import Mecab\n","from konlpy.tag import Okt # 구 Twitter\n","\n","\n","!pip install pyprind\n","import pyprind\n","\n","\n","import os\n","import math\n","\n","\n","# 말뭉치 fam\n","from konlpy.corpus import kolaw\n","from konlpy.corpus import kobill\n","\n","\n","!pip install palettable\n","!pip install colorbrewer\n","\n","from wordcloud import ImageColorGenerator\n","\n","\n","import random\n","from palettable.colorbrewer.sequential import Reds_9\n","from palettable.colorbrewer.diverging import RdYlBu_11\n","from palettable.colorbrewer.qualitative import Pastel2_8\n","\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import nltk\n","nltk.download('book', quiet=True)\n","from nltk.book import * # text1 부터 text9까지 다양한 텍스트가 제공\n","\n","nltk.corpus.gutenberg.fileids() #저작권이 말소된 문학작품을 포함하는 구텐베르그 말뭉치를 확인\n","nltk.corpus.gutenberg.raw('shakespeare-hamlet.txt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","from nltk.tag import pos_tag\n","from nltk import sent_tokenize\n","from nltk import word_tokenize\n","\n","# 원형 찾아주기\n","from nltk.stem import LancasterStemmer\n","from nltk.stem import WordNetLemmatizer # 위 stemmer보단, 아래 lemmatizer가 성능이 좋음. 단 후자의 경우 품사 지정해줘야!\n","\n","from nltk.tag import pos_tag\n","from nltk import FreqDist\n","from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","\n","# KoNLPy\n","# NLTK는 영어 정보처리를 위한 패키지\n","# 반면, KoNLPy는 한국어 정보처리를 위한 패키지임\n","\n","# 서울대학교 산업공학과가 개발한 형탯호 분석기\n","# 래퍼 피키지인데, 이미 개발된 한글 형태소 분석기를\n","# 파이썬에서 바로 사용할 수 있도록 도와줌\n","\n","# 현재까지 지원하는 형태소 분석기는 모두 5가지\n","# => Hannanum, Kkma, Komoran, Mecab , Okt (구 Twitter)\n","\n","# konlpy-ko.readthedocs.io \n","# konlpy.org\n","\n","# KoNLPy 설치 전 필수 패키지가 JPype1인데\n","# Visual C++ 14 버전 필요!! => visualstudio\n","# ==> 하지만, 미리 컴파일된 ㅍ ㅐ키지가 배포됨\n","# www.lfd.uci.edu/~gohlke/pythonlibs\n","# JPype1 패키지를 다운로드한 후 설치함\n","# JPype1‑0.7.0‑cp36‑cp36m‑win_amd64.whl\n","\n","# !pip install JPype1‑0.7.0‑cp36‑cp36m‑win_amd64.whl\n","\n","# colab에서는 위 JPype1 별도설치 안해도 됨\n","\n","\n","\n","\n","\n","# 다양한 색상 팔레트를 이용한 워드클라우드\n","# jiffyclub.github.io/palettable\n","\n","# 여러가지 배색들을 도와주는 패키지\n","\n","!pip install palettable\n","!pip install colorbrewer\n","\n","from wordcloud import ImageColorGenerator\n","\n","\n","import numpy as np\n","from PIL import Image\n","# KoNLPy\n","\n","# NLTK 는 영어 정보처리를 위한 패키지\n","# 반면, KoNLPy 는 한국어 정보처리를 위한 패키지임\n","\n","# 서울대학교 산업공학과에서 개발한 형태소 분석기 래퍼 패키지인데,\n","# 이미 개발된 한글 형태소 분석기를 파이썬에서 바로 사용할 수 있도록 도와줌\n","\n","# 현재까지 지원하는 형태소 분석기는 모두 5가지\n","# => Hannanum, Kkma, Komoran, mecab, Okt\n","\n","# konlpy-ko.readthedocs.io / konlpy.org\n","\n","# konlpy 설치전 필수 패키지가 JPype1 인데\n","# Visual C++ 14 버젼 필요!! => visualstudio\n","# ==> 하지만, 미리 컴파일된 패키지가 배포됨\n","\n","# www.lfd.uci.edu/~gohlke/pythonlibs 에서\n","# JPype1 검색후 패키지를 다운로드한 후 설치함\n","\n","# pip install JPype1-0.7.0-cp36-cp36m-win_amd64.whl => 콜랩아닌 프로그램에서 설치\n","# pip install konlpy import matplotlib.pyplot as plt\n","\n","# 다양한 머신러닝 알고리즘을 이용.\n","# 교차검증 방식으로 모델을 훈련시키고 예측 정확도를 평가해 줌\n","\n","import nltk\n","nltk.download('stopwords') # 불용어 사전 다운로드\n","\n","# 베이즈 관련\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.naive_bayes import BernoulliNB \n","from sklearn.naive_bayes import GaussianNB\n","\n","\n","\n","\n","from nltk.corpus import stopwords\n","stopWords = stopwords.words('english')\n","\n","import pydotplus \n","from sklearn import tree\n","\n","\n","import math\n","import re\n","import sklearn\n","import image\n","import seaborn as sns\n","\n","\n","from sklearn.preprocessing import LabelBinarizer\n","\n","\n","from matplotlib.colors import ListedColormap\n","\n","import matplotlib.image as pltimg\n","\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.datasets import load_iris\n","from sklearn.datasets import load_boston\n","from sklearn.datasets import load_diabetes\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.datasets import load_digits\n","from sklearn.datasets import fetch_lfw_people\n","from sklearn.datasets import make_blobs\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","import numpy as np\n","import pandas as pd\n","from pandas.plotting import scatter_matrix\n","import matplotlib.pyplot as plt\n","from sklearn.base import BaseEstimator\n","from sklearn.datasets import load_digits\n","\n","# predictive modeling 계열 (의사결정나무, 랜덤포레스트, 로지스틱 회귀, Knearest 등) <- Kmeans 어따 빼먹음\n","from sklearn.tree import DecisionTreeClassifier\n","# 의사결정트리 결정영역을 표시하기 위해 mlxtend 패키지 설치\n","from mlxtend.plotting import plot_decision_regions\n","from scipy.stats import entropy #엔트로피\n","\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","\n","# 의사결정트리 결정영역을 표시하기 위해 mlxtend 패키지 설치\n","from mlxtend.plotting import plot_decision_regions\n","\n","# 모델 검증 관련 (정확도)\n","from sklearn.metrics import accuracy_score\n","\n","# preprocessing (전처리) 그룹\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import RobustScaler \n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","# from kmeans_eval import visualize_silhouette <-------- 오류 남. 확인 필요\n","\n","\n","# pandas 출력 설정 : 출력시 가로 생략 없애기\n","# pd.set_option('display.max_columns', 50)\n","# pd.set_option('display.width',250)\n","pd.set_option('display.expand_frame_repr', False) \n","# 바로 위 1줄이면 그 위위 2줄과 동일\n","\n","from sklearn.base import BaseEstimator\n","\n","from sklearn.metrics import confusion_matrix # 혼동행렬\n","from pandas.plotting import scatter_matrix\n","from sklearn import metrics\n","\n","\n","from sklearn.linear_model import Lasso\n","from sklearn.linear_model import Ridge\n","\n","!pip install mglearn\n","import mglearn \n","!pip install mlxtend\n","\n","# score류 (predictive modeling을 평가하는 지표)\n","from sklearn.metrics import accuracy_score # 정확도\n","from sklearn.metrics import precision_score # 정밀도\n","from sklearn.metrics import recall_score # 민감도(재현율)\n","from  sklearn.metrics import f1_score # F1 스코어 (정밀도, 민감도 조화평균..)\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import r2_score\n","\n","from sklearn.metrics import mean_squared_error\n","\n","\n","\n","\n","\n","\n","# Vectorizer \n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","\n","# ROC\n","\n","# Receiver Operation Characteristics Curve\n","# 수신자 판단 곡선\n","\n","# 세계 2차 대전 통신 장비 성능 평가를 위해 고안된 수치\n","# 의학분야에 많이 사용되지만, 머신러닝의 이진 분류 모델 예측 성능 평가에도 사용\n","\n","# 특이도(FPR)가 변할 때 민감도가 어떻게 변하는지 알아보기 위한 곡선\n","\n","# 환자 중 보균자p/정상인n 있는 경우\n","# 재현율 : 보균자를 보균자로 양성 판정\n","# 특이도 : 정상인을 정상인으로 음성 판정\n","\n","# -_-;;; -------------------------------------------------------------------------------\n","\n","\n","# AUC \n","\n","# Area Under Curve\n","# ROC 곡선 밑의 면적을 구한 값\n","# 1에 가까울수록 좋은 수치를 의미함\n","\n","\n","## 리지, 라쏘 회귀 - 과적합을 피하기 위함\n","\n","# 가중치에 계약조건을 설정해서 회귀를 구하는 알고리즘\n","# 이를 통해 모델의 복잡도를 다소 낮춰 적당한 편향/분산을 통해\n","# 적절한 회귀모델을 구함\n","\n","# 일반적인 회귀분석 : 회귀계수 추정량을 구함\n","# 잔차의 제곱합을 최소로 하는 최소제곱법 사용\n","\n","# 실제 회귀모델은 단일변수가 아닌 다중변수가 많음\n","\n","# 독립변수 증가 => 변수간 강한 상관관계 => 다중공선성 문제 발생\n","# => 최소제곱법을 이용한 회귀계수 추정량이 커짐 => 정확도 저하\n","\n","# 따라서, 중요한 변수를 선정하고, 중요하지 않은 변수는 제외\n","# => 변수선택(feature selection)\n","# 중요하지 않은 변수에 해당하는 계수 절대값을 낮춤\n","\n","\n","\n","## 라쏘회귀(L1 패널티)\n","# 원래의 최소제곱법에 제약을 가함\n","# 중요하지 않은 변수의 계수는 축소 => 0으로 설정\n","# 기울기를 완전히 줄여 특정 특성이 모델에 주는 영향을 제외시킴\n","\n","\n","## 리지회귀(L2 패널티)\n","# 원래의 최소제곱법에 제약을 가함\n","# 중요하지 않은 변수의 계수는 축소 => 0에 가깝게 설정\n","# 기울기를 다소 줄여 특정 특성이 모델에 주는 영향을 축소시킴\n","\n","\n","## 엘라스틱넷 회귀\n","# 라쏘회귀와 리지회귀의 제약을 합친 모형\n","\n","from sklearn.linear_model import Lasso\n","from sklearn.linear_model import Ridge\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: palettable in /usr/local/lib/python3.6/dist-packages (3.2.0)\n","Requirement already satisfied: colorbrewer in /usr/local/lib/python3.6/dist-packages (0.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from colorbrewer) (1.12.0)\n","*** Introductory Examples for the NLTK Book ***\n","Loading text1, ..., text9 and sent1, ..., sent9\n","Type the name of the text or sentence to view it.\n","Type: 'texts()' or 'sents()' to list the materials.\n","text1: Moby Dick by Herman Melville 1851\n","text2: Sense and Sensibility by Jane Austen 1811\n","text3: The Book of Genesis\n","text4: Inaugural Address Corpus\n","text5: Chat Corpus\n","text6: Monty Python and the Holy Grail\n","text7: Wall Street Journal\n","text8: Personals Corpus\n","text9: The Man Who Was Thursday by G . K . Chesterton 1908\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Requirement already satisfied: JPype1>=0.5.7 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.0)\n","Requirement already satisfied: palettable in /usr/local/lib/python3.6/dist-packages (3.2.0)\n","Requirement already satisfied: colorbrewer in /usr/local/lib/python3.6/dist-packages (0.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from colorbrewer) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2_P8gvlFxuCu","colab_type":"code","outputId":"1680083d-e5f2-418a-a9c7-ddd11f1c7843","executionInfo":{"status":"ok","timestamp":1563784368087,"user_tz":-540,"elapsed":836,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}},"colab":{"base_uri":"https://localhost:8080/","height":355}},"source":["##### ------------------ 본 한글주석 by 유형균 (이메일 문의 : quantgeni@gmail.com) ------------------ #####\n","\n","# KoNLPy\n","\n","# NLTK 는 영어 정보처리를 위한 패키지\n","# 반면, KoNLPy 는 한국어 정보처리를 위한 패키지임\n","\n","# 서울대학교 산업공학과에서 개발한 형태소 분석기 래퍼 패키지인데,\n","# 이미 개발된 한글 형태소 분석기를 파이썬에서 바로 사용할 수 있도록 도와줌\n","\n","# 현재까지 지원하는 형태소 분석기는 모두 5가지\n","# => Hannanum, Kkma, Komoran, mecab, Okt\n","\n","# konlpy-ko.readthedocs.io / konlpy.org\n","\n","# konlpy 설치전 필수 패키지가 JPype1 인데\n","# Visual C++ 14 버젼 필요!! => visualstudio\n","# ==> 하지만, 미리 컴파일된 패키지가 배포됨\n","\n","# www.lfd.uci.edu/~gohlke/pythonlibs 에서\n","# JPype1 검색후 패키지를 다운로드한 후 설치함\n","\n","# pip install JPype1-0.7.0-cp36-cp36m-win_amd64.whl => 콜랩아닌 프로그램에서 설치\n","# pip install konlpy \n","\n","##### ------------------ 본 한글주석 by 유형균 (이메일 문의 : quantgeni@gmail.com) ------------------ #####\n","\n","twitter = Okt()\n","# 트위터 형태소 사전을 사용하기 위해 초기화\n","\n","txt1 = '아버지가 방에 들어가신다'\n","txt2 = '나는 보리밥을 먹었다'\n","txt3 = '롯데마트가 판매하고 있는 흑마늘 양념치킨이 논란이 되고 있다'\n","\n","# 형태소 분석\n","# pos() 주요 품사 기반 추출\n","\n","print(twitter.pos(txt1))\n","print()\n","print(twitter.pos(txt2))\n","print()\n","print(twitter.pos(txt3))\n","print('-------------------------------------------------------------------------------------------------------')\n","\n","# 형태소 분석\n","# morphs() 상세 품사 기반 추출\n","print(twitter.morphs(txt1))\n","print()\n","print(twitter.morphs(txt2))\n","print()\n","print(twitter.morphs(txt3))\n","print('-------------------------------------------------------------------------------------------------------')\n","\n","# 형태소 분석\n","# nouns() 명사 기반 추출\n","# 출력물을 보면, preprocessing에 있어 상당히 편리하다는 것을 알 수 있다\n","print(twitter.nouns(txt1))\n","print()\n","print(twitter.nouns(txt2))\n","print()\n","print(twitter.nouns(txt3))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('아버지', 'Noun'), ('가', 'Josa'), ('방', 'Noun'), ('에', 'Josa'), ('들어가신다', 'Verb')]\n","\n","[('나', 'Noun'), ('는', 'Josa'), ('보리밥', 'Noun'), ('을', 'Josa'), ('먹었다', 'Verb')]\n","\n","[('롯데', 'Noun'), ('마트', 'Noun'), ('가', 'Josa'), ('판매', 'Noun'), ('하고', 'Josa'), ('있는', 'Adjective'), ('흑마', 'Noun'), ('늘', 'Noun'), ('양념치킨', 'Noun'), ('이', 'Josa'), ('논란', 'Noun'), ('이', 'Josa'), ('되고', 'Verb'), ('있다', 'Adjective')]\n","-------------------------------------------------------------------------------------------------------\n","['아버지', '가', '방', '에', '들어가신다']\n","\n","['나', '는', '보리밥', '을', '먹었다']\n","\n","['롯데', '마트', '가', '판매', '하고', '있는', '흑마', '늘', '양념치킨', '이', '논란', '이', '되고', '있다']\n","-------------------------------------------------------------------------------------------------------\n","['아버지', '방']\n","\n","['나', '보리밥']\n","\n","['롯데', '마트', '판매', '흑마', '늘', '양념치킨', '논란']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AJG3hTEjzeFX","colab_type":"code","outputId":"f382c2f7-47fd-4984-943e-a46dc8269972","executionInfo":{"status":"ok","timestamp":1563787963550,"user_tz":-540,"elapsed":883,"user":{"displayName":"얍얍","photoUrl":"","userId":"00095991694523741423"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["##### ------------------ 본 한글주석 by 유형균 (이메일 문의 : quantgeni@gmail.com) ------------------ #####\n","# 대한민국 헌법 말뭉치를 이용해서 워드클라우드로 시각화해 봄\n","# KoNLPy 내장 한국어 말뭉치\n","# 대한민국 헌법 말뭉치 : kolaw\n","# 국회법안 말뭉치 : kobill\n","\n","from konlpy.corpus import kolaw\n","from konlpy.corpus import kobill\n","\n","kolaw.fileids() # 말뭉치 이름 출력\n","kobill.fileids()\n","\n","doc1 = kolaw.open('constitution.txt').read()\n","print(doc1[:100]) # 100자까지 확인\n","print('-----------------------------------------------------------------------------------')\n","doc2 = kobill.open('1809895.txt').read()\n","print(doc2[:100]) # 100자까지 확인"],"execution_count":0,"outputs":[{"output_type":"stream","text":["대한민국헌법\n","\n","유구한 역사와 전통에 빛나는 우리 대한국민은 3·1운동으로 건립된 대한민국임시정부의 법통과 불의에 항거한 4·19민주이념을 계승하고, 조국의 민주개혁과 평화적 통일의\n","-----------------------------------------------------------------------------------\n","하도급거래 공정화에 관한 법률 일부개정법률안\n","\n","(유선호의원 대표발의 )\n","\n"," 의 안\n"," 번 호\n","\n","9895\n","\n","발의연월일 : 2010.  11.  15.\n","\n","발  의  자 : 유선호․강기갑\n"],"name":"stdout"}]}]}